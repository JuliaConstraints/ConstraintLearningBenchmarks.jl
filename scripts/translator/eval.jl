using DrWatson
@quickactivate "ICNBenchmarks"

using ConstraintExplorer
using ConstraintsTranslator
using CSV
using DataFrames
using JSON3
using JuMP
using Pkg

DATASET_DIR = joinpath(dirname(pathof(ConstraintsTranslator)), "..", "dataset")
PROMPTS_DIR = joinpath(DATASET_DIR, "prompts")
GT_DIR = joinpath(DATASET_DIR, "ground_truth")
INSTANCES_DIR = joinpath(GT_DIR, "instances")
CONFIGURATIONS_DIR = joinpath(GT_DIR, "configurations")

PROBLEM_NAMES = [
    "traveling_salesman",
]

for problem_name in PROBLEM_NAMES, llm in [GoogleLLM("gemini-1.5-flash")]
    problem_file = joinpath(PROMPTS_DIR, "$problem_name.txt")
    prompt = String(read(problem_file))
    code = translate(llm, prompt)
    code_expr = Meta.parse(code)
    func_expr = code_expr.args[end]
    func_name = func_expr.args[1].args[1]
    eval(code_expr)
    f = eval(func_name)
    instances_path = joinpath(INSTANCES_DIR, problem_name)
    instances = sort(readdir(instances_path, join=true))
    for instance in instances
        # We need to sort to provide the input files in the correct expected order to the function generated by the LLM
        # There is probably a better way to do this by using kwargs
        instance_data = sort(readdir(instance, join=true))
        model = f(instance_data...)
        set_optimizer(model, ConstraintExplorer.Optimizer)
        configurations = readdir(CONFIGURATIONS_DIR * "/" * problem_name, join=true)
        configuration = first(configurations)
        configuration_data = JSON3.read(configuration)
        solutions = Vector(configuration_data[:solutions])
        non_solutions = Vector(configuration_data[:non_solutions])
        check!(model, [solutions; non_solutions])
    end
end
